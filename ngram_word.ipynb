{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "typical-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "text = \"\"\"Global warming or climate change has become a worldwide concern. It is gradually developing into an unprecedented environmental crisis evident in melting glaciers, changing weather patterns, rising sea levels, floods, cyclones and droughts. Global warming implies an increase in the average temperature of the Earth due to entrapment of greenhouse gases in the earth’s atmosphere.\"\"\"\n",
    "\n",
    "ngrams = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "auburn-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seven-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #we are going to need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "herbal-bahamas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Global', 'warming', 'or', 'climate', 'change', 'has', 'become', 'a', 'worldwide', 'concern', '.', 'It', 'is', 'gradually', 'developing', 'into', 'an', 'unprecedented', 'environmental', 'crisis', 'evident', 'in', 'melting', 'glaciers', ',', 'changing', 'weather', 'patterns', ',', 'rising', 'sea', 'levels', ',', 'floods', ',', 'cyclones', 'and', 'droughts', '.', 'Global', 'warming', 'implies', 'an', 'increase', 'in', 'the', 'average', 'temperature', 'of', 'the', 'Earth', 'due', 'to', 'entrapment', 'of', 'greenhouse', 'gases', 'in', 'the', 'earth', '’', 's', 'atmosphere', '.']\n"
     ]
    }
   ],
   "source": [
    "#for character based we could just loop through the text but when we are working with words then we can't do that\n",
    "#then we need an explicit list of words i.e., all the words that are contined in this text and we can loop through it\n",
    "words = nltk.word_tokenize(text) #we will get list of words this way\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "scientific-number",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Global warming or': ['climate'],\n",
       " 'warming or climate': ['change'],\n",
       " 'or climate change': ['has'],\n",
       " 'climate change has': ['become'],\n",
       " 'change has become': ['a'],\n",
       " 'has become a': ['worldwide'],\n",
       " 'become a worldwide': ['concern'],\n",
       " 'a worldwide concern': ['.'],\n",
       " 'worldwide concern .': ['It'],\n",
       " 'concern . It': ['is'],\n",
       " '. It is': ['gradually'],\n",
       " 'It is gradually': ['developing'],\n",
       " 'is gradually developing': ['into'],\n",
       " 'gradually developing into': ['an'],\n",
       " 'developing into an': ['unprecedented'],\n",
       " 'into an unprecedented': ['environmental'],\n",
       " 'an unprecedented environmental': ['crisis'],\n",
       " 'unprecedented environmental crisis': ['evident'],\n",
       " 'environmental crisis evident': ['in'],\n",
       " 'crisis evident in': ['melting'],\n",
       " 'evident in melting': ['glaciers'],\n",
       " 'in melting glaciers': [','],\n",
       " 'melting glaciers ,': ['changing'],\n",
       " 'glaciers , changing': ['weather'],\n",
       " ', changing weather': ['patterns'],\n",
       " 'changing weather patterns': [','],\n",
       " 'weather patterns ,': ['rising'],\n",
       " 'patterns , rising': ['sea'],\n",
       " ', rising sea': ['levels'],\n",
       " 'rising sea levels': [','],\n",
       " 'sea levels ,': ['floods'],\n",
       " 'levels , floods': [','],\n",
       " ', floods ,': ['cyclones'],\n",
       " 'floods , cyclones': ['and'],\n",
       " ', cyclones and': ['droughts'],\n",
       " 'cyclones and droughts': ['.'],\n",
       " 'and droughts .': ['Global'],\n",
       " 'droughts . Global': ['warming'],\n",
       " '. Global warming': ['implies'],\n",
       " 'Global warming implies': ['an'],\n",
       " 'warming implies an': ['increase'],\n",
       " 'implies an increase': ['in'],\n",
       " 'an increase in': ['the'],\n",
       " 'increase in the': ['average'],\n",
       " 'in the average': ['temperature'],\n",
       " 'the average temperature': ['of'],\n",
       " 'average temperature of': ['the'],\n",
       " 'temperature of the': ['Earth'],\n",
       " 'of the Earth': ['due'],\n",
       " 'the Earth due': ['to'],\n",
       " 'Earth due to': ['entrapment'],\n",
       " 'due to entrapment': ['of'],\n",
       " 'to entrapment of': ['greenhouse'],\n",
       " 'entrapment of greenhouse': ['gases'],\n",
       " 'of greenhouse gases': ['in'],\n",
       " 'greenhouse gases in': ['the'],\n",
       " 'gases in the': ['earth'],\n",
       " 'in the earth': ['’'],\n",
       " 'the earth ’': ['s'],\n",
       " 'earth ’ s': ['atmosphere'],\n",
       " '’ s atmosphere': ['.']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(words)-n): #going through list leaving the last n\n",
    "    gram = ' '.join(words[i:i+n]) #for words we have to do this\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram]=[]\n",
    "    ngrams[gram].append(words[i+n])\n",
    "    \n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sorted-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global warming or climate change has become a worldwide concern . It is gradually developing into an unprecedented environmental crisis evident in melting glaciers , changing weather patterns , rising sea levels ,\n"
     ]
    }
   ],
   "source": [
    "#Testing \n",
    "currentGram = ' '.join(words[0:n]) #joining first n words (starting point)\n",
    "result = currentGram\n",
    "for i in range(30):  #last time we built a string of 100 here we can't do that we have to specify no. of words (30)\n",
    "    if currentGram not in ngrams.keys():\n",
    "        break\n",
    "    possibilities = ngrams[currentGram] #this will give the list of words that will follow currentGram\n",
    "    nextItem = possibilities[random.randrange(len(possibilities))]\n",
    "    result += ' '+nextItem #when working with words different words have to be sperated by space\n",
    "    rwords = nltk.word_tokenize(result)\n",
    "    currentGram = ' '.join(rwords[len(rwords)-n:len(rwords)])\n",
    "    \n",
    "    \n",
    "print(result)\n",
    "#you can see how accurate it is almost 100 % this is because we have a very small text but if you do this in an\n",
    "#article of wikipedia you will see it is not that accurate to make it more accurate you have to increase the n value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
